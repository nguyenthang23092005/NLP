# Vietnamese Text Summarization with mT5

Dá»± Ã¡n fine-tune mÃ´ hÃ¬nh mT5 cho tÃ³m táº¯t vÄƒn báº£n tiáº¿ng Viá»‡t vá»›i LoRA vÃ  CPO.

## ğŸ“‹ Tá»•ng quan

- **MÃ´ hÃ¬nh base**: google/mt5-small
- **Ká»¹ thuáº­t**: LoRA (Parameter-Efficient Fine-Tuning) + CPO (Contrastive Preference Optimization)
- **Dataset**: Vietnamese news articles (80k+ samples)
- **Framework**: HuggingFace Transformers, PEFT, TRL

## ğŸš€ CÃ i Ä‘áº·t

```bash
# Clone repository
git clone <repo-url>
cd NLP

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# Kiá»ƒm tra GPU
python check_gpu.py
```

## ğŸ“Š Chuáº©n bá»‹ dá»¯ liá»‡u

```bash
# Xá»­ lÃ½ raw data thÃ nh processed_dataset.json
python data_processing.py

# Táº¡o train/test/validation splits
python recreate_splits.py
```

Dá»¯ liá»‡u sau khi xá»­ lÃ½:
- `data/processed_dataset.json`: Dá»¯ liá»‡u Ä‘Ã£ clean
- `data/splits/`: Train/test/validation splits (80/10/10)
- `data/cpo_splits/`: Preference pairs cho CPO training

## ğŸ¯ Training

### 1. Training LoRA (SFT)

```bash
# Full dataset
python train_lora.py

# Quick test vá»›i 1000 samples
python train_lora.py --max_samples 1000 --num_train_epochs 3 --output_dir ./models/mt5-lora-1k
```

### 2. Training CPO

```bash
# Train CPO trÃªn model Ä‘Ã£ fine-tune LoRA
python train_cpo.py --model_path ./models/mt5-lora-full
```

### 3. Two-Stage Training (SFT + CPO)

```bash
# Tá»± Ä‘á»™ng train 2 giai Ä‘oáº¡n
python train_two_stage.py --max_samples 5000 --sft_num_epochs 5 --cpo_num_epochs 3
```

### Tham sá»‘ quan trá»ng

| Tham sá»‘ | SFT | CPO | MÃ´ táº£ |
|---------|-----|-----|-------|
| `--max_samples` | âœ“ | âœ“ | Sá»‘ samples train (None = full) |
| `--num_train_epochs` | âœ“ | - | Sá»‘ epochs cho SFT |
| `--learning_rate` | âœ“ | âœ“ | Learning rate (1e-4 cho SFT, 5e-5 cho CPO) |
| `--batch_size` | âœ“ | âœ“ | Batch size per device |
| `--output_dir` | âœ“ | âœ“ | ThÆ° má»¥c lÆ°u model |

## ğŸ“ˆ ÄÃ¡nh giÃ¡

```bash
# Evaluate model trÃªn test set
python evaluate_model.py \
    --model_path ./models/mt5-lora-full/checkpoint-7728 \
    --data_path data/splits \
    --split test \
    --output_file predictions_lora.jsonl

# So sÃ¡nh nhiá»u models
python compare_models.py
```

Metrics: ROUGE-1, ROUGE-2, ROUGE-L

## ğŸŒ Web Interface

```bash
# Cháº¡y Streamlit app
streamlit run app.py
```

Features:
- Upload file (PDF, DOC, DOCX) hoáº·c nháº­p text
- Chá»n model (LoRA SFT, CPO, DPO, Base mT5)
- Xem vÃ  táº£i káº¿t quáº£ tÃ³m táº¯t
- Hiá»ƒn thá»‹ thá»‘ng kÃª Ä‘á»™ dÃ i

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
NLP/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed_dataset.json      # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
â”‚   â”œâ”€â”€ splits/                     # Train/test/val splits
â”‚   â””â”€â”€ cpo_splits/                 # CPO preference pairs
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mt5-lora-full/             # Model LoRA full dataset
â”‚   â”œâ”€â”€ mt5-lora-1k/               # Model LoRA 1k samples
â”‚   â””â”€â”€ mt5-lora-cpo/              # Model sau CPO
â”œâ”€â”€ train_lora.py                   # Training script LoRA
â”œâ”€â”€ train_cpo.py                    # Training script CPO
â”œâ”€â”€ train_two_stage.py              # 2-stage training
â”œâ”€â”€ evaluate_model.py               # ÄÃ¡nh giÃ¡ model
â”œâ”€â”€ app.py                          # Streamlit web app
â””â”€â”€ data_processing.py              # Xá»­ lÃ½ raw data
```

## ğŸ”§ Scripts há»— trá»£

- `check_gpu.py`: Kiá»ƒm tra GPU availability vÃ  VRAM
- `check_data.py`: Xem thá»‘ng kÃª dataset
- `recreate_splits.py`: Táº¡o láº¡i train/test/val splits
- `visualization.ipynb`: Visualize training metrics

## ğŸ’¡ Tips

**Äá»ƒ train nhanh vá»›i Ã­t dá»¯ liá»‡u:**
```bash
python train_lora.py --max_samples 1000 --num_train_epochs 3 --output_dir ./models/test
```

**Äá»ƒ train full vá»›i best performance:**
```bash
python train_two_stage.py --sft_num_epochs 5 --cpo_num_epochs 3
```

**Náº¿u thiáº¿u VRAM:**
- Giáº£m `--per_device_train_batch_size` xuá»‘ng 2 hoáº·c 1
- TÄƒng `--gradient_accumulation_steps` lÃªn 8 hoáº·c 16

## ğŸ“ TÃ i liá»‡u thÃªm

- [TRAIN_EXPLAINED.md](TRAIN_EXPLAINED.md): Chi tiáº¿t vá» training process
- [CPO_EXPLAINED.md](CPO_EXPLAINED.md): Giáº£i thÃ­ch CPO algorithm
- [DPO_EXPLAINED.md](DPO_EXPLAINED.md): Giáº£i thÃ­ch DPO algorithm
- [QUICKSTART.md](QUICKSTART.md): HÆ°á»›ng dáº«n nhanh
- [APP_GUIDE.md](APP_GUIDE.md): HÆ°á»›ng dáº«n sá»­ dá»¥ng web app

## ğŸ“Š Káº¿t quáº£

| Model | ROUGE-1 | ROUGE-2 | ROUGE-L |
|-------|---------|---------|---------|
| Base mT5 | - | - | - |
| LoRA SFT | - | - | - |
| LoRA + CPO | - | - | - |

*(Cháº¡y evaluate_model.py Ä‘á»ƒ cáº­p nháº­t)*

## ğŸ¤ Contributing

Pull requests welcome! HÃ£y Ä‘áº£m báº£o code cá»§a báº¡n:
- Follow PEP 8 style guide
- CÃ³ docstrings cho functions
- Test trÆ°á»›c khi commit

## ğŸ“„ License

MIT License